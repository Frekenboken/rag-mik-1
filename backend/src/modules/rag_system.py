from src.modules.llm import LLM, context_prompt
from src.modules.rerank import Rerank
from src.modules.text_embedder import TextEmbedder
from src.modules.semantic_search import SemanticSearch
from src.modules.document_tools import DocumentsLoader, Chunker
from src.modules.rag_exeptions import DimensionMismatch, ModuleLoadingFailure
from langchain_community.document_loaders import DirectoryLoader, TextLoader
import faiss
import pickle
import numpy as np
import time
import json


class RAG:
    def __init__(
            self,
            question_path,
            docs_path,
            vdb_path,
            file_type
    ):
        self.question_path = question_path
        self.docs_path = docs_path
        self.vdb_path = vdb_path
        self.file_type = file_type
        print('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...')
        try:
            self.rerank = Rerank()
        except:
            raise ModuleLoadingFailure(Rerank)
        try:
            self.llm = LLM(context_prompt)
        except:
            raise ModuleLoadingFailure(LLM)
        try:
            self.embedder = TextEmbedder()
        except:
            raise ModuleLoadingFailure(TextEmbedder)
        try:
            self.chunker = Chunker()
        except:
            raise ModuleLoadingFailure(Chunker)
        try:
            self.documents_loader = DocumentsLoader(DirectoryLoader, TextLoader, docs_path, file_type)
            self.questions_loader = DocumentsLoader(DirectoryLoader, TextLoader, question_path, file_type)
        except:
            raise ModuleLoadingFailure(DocumentsLoader)

        print('–ü–æ–∏—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...')
        try:
            with open(docs_path + '../' + 'docs.bin', 'rb') as docs:
                self.docs = pickle.load(docs)
            with open(docs_path + '../' + 'all_chunks.bin', 'rb') as all_chunks:
                self.all_chunks = pickle.load(all_chunks)
            with open(docs_path + '../' + 'chunks_with_meta.bin', 'rb') as chunks_with_meta:
                self.chunks_with_meta = pickle.load(chunks_with_meta)
            with open(question_path + '../' + 'processed_questions.bin', 'rb') as processed_questions:
                self.processed_questions = pickle.load(processed_questions)
            print('–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã!')
        except FileNotFoundError:
            print('–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...')
            self.docs = self.documents_loader.process_docs()
            self.questions = self.questions_loader.process_docs()
            self.all_chunks, self.chunks_with_meta = self.chunker.advanced_separate_on_chunks(self.docs)
            self.processed_questions = self.chunker.questions_process(self.questions)
            with open(docs_path + '../' + 'docs.bin', 'wb') as docs:
                pickle.dump(self.docs, docs)
            with open(docs_path + '../' + 'all_chunks.bin', 'wb') as all_chunks:
                pickle.dump(self.all_chunks, all_chunks)
            with open(docs_path + '../' + 'chunks_with_meta.bin', 'wb') as chunks_with_meta:
                pickle.dump(self.chunks_with_meta, chunks_with_meta)
            with open(question_path + '../' + 'questions.bin', 'wb') as questions:
                pickle.dump(self.questions, questions)
            print('–ó–∞–≤–µ—Ä—à–µ–Ω–æ!')

        print("–ü–æ–∏—Å–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        try:
            embeddings = np.load(self.vdb_path + 'embeddings.npy')
            print("–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞–π–¥–µ–Ω—ã!")
        except:
            print("–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
            embeddings = self.embedder.get_embeddings(self.all_chunks)
            np.save(self.vdb_path + 'embeddings.npy', embeddings, allow_pickle=False, fix_imports=False)
            print("–ó–∞–≤–µ—Ä—à–µ–Ω–æ!")

        dimension = embeddings.shape[1]

        print("–ü–æ–∏—Å–∫ –∏–Ω–¥–µ–∫—Å–∞...")
        try:
            self.index = faiss.read_index(self.vdb_path + "index.index")
            print("–ò–Ω–¥–µ–∫—Å –Ω–∞–π–¥–µ–Ω!")
        except:
            print("–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω\n–°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å...")
            self.index = faiss.IndexFlatIP(dimension)
            self.index.add(embeddings)
            faiss.write_index(self.index, self.vdb_path + "index.index")
            print("–ó–∞–≤–µ—Ä—à–µ–Ω–æ!")

        if self.index.d == dimension:
            print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {dimension}")
        else:
            raise DimensionMismatch(dimension, self.index.d)

        try:
            self.semantic_search = SemanticSearch(self.index, self.chunks_with_meta, self.rerank, self.embedder)
        except:
            raise ModuleLoadingFailure(SemanticSearch)
        print('RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞')

    def interaction(self, query, history, k=3, d=2):
        context = set(self.semantic_search.search(query, k=k)[:d])
        response = self.llm.context_response(history, ''.join([chunk[0] for chunk in context]), query)
        return response.content + ('\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: ' + ', '.join(
            [f'{source}, –†–∞–∑–¥–µ–ª {x_topic}.{s_topic}' for chunk, s_topic, x_topic, source in
             context]) if context != [] else '')

    def semsearch_debug(self, query, k):
        self.semantic_search.search_debuging(query, k=k)

    def keyword_extraction_debug(self, query):
        print(self.semantic_search.extract_keywords(query))

    def one_ans_rate(self, quest):
        query = quest[2]
        category = quest[1]
        ind = quest[0]
        expected_answer = quest[3]
        start_time = time.time()
        actual_answer = self.interaction(query, '')
        response_time = time.time() - start_time
        # –†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏
        similarity = self.semantic_search.calculate_similarity(
            actual_answer,
            expected_answer
        )

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–∞–ª–ª–æ–≤
        if similarity >= 0.8:
            score = 0.8  # –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
            status = "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ"
        elif similarity >= 0.5:
            score = 0.4  # –ß–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
            status = "‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ"
        else:
            score = 0  # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
            status = "‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ"

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        has_sources = '–ò—Å—Ç–æ—á–Ω–∏–∫–∏' in actual_answer

        return {
            'question_id': ind,
            'category': category,
            'question': query,
            'expected_answer': expected_answer,
            'received_answer': actual_answer,
            'similarity': similarity,
            'score': score,
            'status': status,
            'has_sources': has_sources,
            'confidence': 100,
            'response_time': response_time,
            'error': 'everytime'
        }, actual_answer

    def rag_rating(self):
        results = []
        print("\n" + "=" * 60)
        print("üöÄ –ó–ê–ü–£–°–ö –û–¶–ï–ù–ö–ò RAG-–°–ò–°–¢–ï–ú–´ –ú–ò–ö-1")
        print("=" * 60 + "\n")

        total_score = 0
        category_scores = {}

        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        for i, test_q in enumerate(self.processed_questions, 1):
            query = test_q[2]
            category = test_q[1]
            print(f"üìù –¢–µ—Å—Ç {i}/{len(self.processed_questions)}: {query[:50]}...")

            result, res = self.one_ans_rate(test_q)
            print(f"–û—Ç–≤–µ—Ç: {res[:100]}")

            results.append(result)
            total_score += result['score']

            if category not in category_scores:
                category_scores[category] = {'total': 0, 'earned': 0, 'count': 0}
            category_scores[category]['total'] += 0.8
            category_scores[category]['earned'] += result['score']
            category_scores[category]['count'] += 1

            print(f"   {result['status']} | –°—Ö–æ–∂–µ—Å—Ç—å: {result['similarity']:.2%} | –ë–∞–ª–ª—ã: {result['score']}")

            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(0.5)

        max_possible = len(self.processed_questions) * 0.8

        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_percentages = {}
        for cat, scores in category_scores.items():
            percentage = (scores['earned'] / scores['total']) * 100 if scores['total'] > 0 else 0
            category_percentages[cat] = {
                'percentage': percentage,
                'earned': scores['earned'],
                'total': scores['total'],
                'count': scores['count']
            }

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            correct_answers = sum(1 for r in results if r['score'] == 0.8)
            partial_answers = sum(1 for r in results if r['score'] == 0.4)
            wrong_answers = sum(1 for r in results if r['score'] == 0)

            avg_confidence = sum(r['confidence'] for r in results) / len(results) if results else 0
            avg_response_time = sum(r['response_time'] for r in results) / len(results) if results else 0

            final_results = {
                'total_score': total_score,
                'max_possible': max_possible,
                'percentage': (total_score / max_possible * 100) if max_possible > 0 else 0,
                'questions_tested': len(self.processed_questions),
                'correct_answers': correct_answers,
                'partial_answers': partial_answers,
                'wrong_answers': wrong_answers,
                'category_scores': category_percentages,
                'avg_confidence': avg_confidence,
                'avg_response_time': avg_response_time,
                'detailed_results': results
            }
            print("\n" + "=" * 60)
            print("üìä –û–¢–ß–ï–¢ –û–ë –û–¶–ï–ù–ö–ï RAG-–°–ò–°–¢–ï–ú–´")
            print("=" * 60 + "\n")

            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            print("üéØ –ò–¢–û–ì–û–í–´–ï –ë–ê–õ–õ–´:")
            print(f"   –ù–∞–±—Ä–∞–Ω–æ –±–∞–ª–ª–æ–≤: {final_results['total_score']:.1f} / {final_results['max_possible']:.1f}")
            print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç: {final_results['percentage']:.1f}%")
            print(f"   –û—Ü–µ–Ω–∫–∞: ", end='')
            if final_results['percentage'] >= 90:
                print("üèÜ –û—Ç–ª–∏—á–Ω–æ (A)")
            elif final_results['percentage'] >= 80:
                print("üëç –•–æ—Ä–æ—à–æ (B)")
            elif final_results['percentage'] >= 70:
                print("‚úîÔ∏è –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ (C)")
            elif final_results['percentage'] >= 60:
                print("‚ö†Ô∏è –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (D)")
            else:
                print("‚ùå –ù–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ (F)")
            print()

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
            print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–¢–í–ï–¢–û–í:")
            print(
                f"   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {final_results['correct_answers']} ({final_results['correct_answers'] / final_results['questions_tested'] * 100:.1f}%)")
            print(
                f"   ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω—ã—Ö: {final_results['partial_answers']} ({final_results['partial_answers'] / final_results['questions_tested'] * 100:.1f}%)")
            print(
                f"   ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {final_results['wrong_answers']} ({final_results['wrong_answers'] / final_results['questions_tested'] * 100:.1f}%)")
            print()

            # –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            print("üìÇ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
            for cat, scores in final_results['category_scores'].items():
                print(f"   {cat}: {scores['percentage']:.1f}% ({scores['earned']:.1f}/{scores['total']:.1f} –±–∞–ª–ª–æ–≤)")
            print()
            # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            print("‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
            print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {final_results['avg_confidence']:.2%}")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {final_results['avg_response_time']:.2f} —Å–µ–∫")
            print()

            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –ø–æ –¢–ó
            print("‚úÖ –°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –ö–†–ò–¢–ï–†–ò–Ø–ú:")
            criteria_met = []
            criteria_not_met = []

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
            if final_results['category_scores'][list(final_results['category_scores'].keys())[0]]['percentage'] >= 90:
                criteria_met.append("‚úì –ü—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã ‚â• 90%")
            else:
                criteria_not_met.append("‚úó –ü—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã < 90%")

            if final_results['category_scores'][final_results['category_scores'].keys()[0]]['percentage'] >= 80:
                criteria_met.append("‚úì –°—Ä–µ–¥–Ω–∏–µ –≤–æ–ø—Ä–æ—Å—ã ‚â• 80%")
            else:
                criteria_not_met.append("‚úó –°—Ä–µ–¥–Ω–∏–µ –≤–æ–ø—Ä–æ—Å—ã < 80%")

            if final_results['category_scores'][final_results['category_scores'].keys()[0]]['percentage'] >= 60:
                criteria_met.append("‚úì –°–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã ‚â• 60%")
            else:
                criteria_not_met.append("‚úó –°–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã < 60%")

            if final_results['percentage'] >= 75:
                criteria_met.append("‚úì –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å ‚â• 75%")
            else:
                criteria_not_met.append("‚úó –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å < 75%")

            for criterion in criteria_met:
                print(f"   {criterion}")
            for criterion in criteria_not_met:
                print(f"   {criterion}")

            print("\n" + "=" * 60)

        compact_results = {k: v for k, v in final_results.items() if k != 'detailed_results'}

        with open('src/rag_evaluation/evaluation_results.json', 'w', encoding='utf-8') as f:
            json.dump(compact_results, f, ensure_ascii=False, indent=2)

        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ evaluation_results.json")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        with open('src/rag_evaluation/evaluation_detailed.txt', 'w', encoding='utf-8') as f:
            f.write("–î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –û–¶–ï–ù–ö–ò RAG-–°–ò–°–¢–ï–ú–´ –ú–ò–ö-1\n")
            f.write("=" * 60 + "\n\n")

            for result in final_results['detailed_results']:
                f.write(f"–í–æ–ø—Ä–æ—Å {result['question_id']}: {result['question']}\n")
                f.write(f"–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç: {result['expected_answer']}\n")
                f.write(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {result['received_answer']}\n")
                f.write(f"–°—Ç–∞—Ç—É—Å: {result['status']} | –°—Ö–æ–∂–µ—Å—Ç—å: {result['similarity']:.2%}\n")
                f.write("-" * 60 + "\n\n")

        print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ evaluation_detailed.txt")
